---
title: "LAB03CDP"
author: "José Glauber"
date: "31 de outubro de 2018"
output: html_document
---

## Importanto os dados e bibliotecas necessárias para as respostas das questões!

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
library(tidyverse)
library(readr)
library(caret)
library(dplyr)
library(ggplot2)
```

# Carregando informações

```{r}
train_set <- read.csv("train.csv", encoding = "latin1")
train <- train_set %>% select(-cargo, -nome, -sequencial_candidato)

test_set <- read.csv("test.csv", encoding = "latin1")
test <- test_set %>% select(-cargo, -nome, -sequencial_candidato)
```
  
## Perguntas

1) Usando todas as variáveis disponíveis, tune (usando validação cruzada): (i) um modelo de regressão Ridge, (ii) um modelo de regressão Lasso e (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos.

i) modelo de regressão Ridge

```{r}
train_control <- trainControl(method = "cv",
                           number = 5)

preProcValues <- c("center", "scale", "nzv")

model.ridge <- train(votos ~ ., 
               data = train,
               trControl = train_control,
               method = "ridge",
               preProcess = preProcValues,
               tuneLength = 15)
model.ridge
```

2) Compare os três modelos em termos do erro RMSE de validação cruzada.

```{r}

```
3) Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?

```{r}

```

4) Re-treine o melhor modelo (usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada).

```{r}

```
